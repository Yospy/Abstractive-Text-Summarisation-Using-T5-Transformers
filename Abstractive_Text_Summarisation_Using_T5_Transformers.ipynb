{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM938KsF0axTj9RkSt5s3hL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yospy/Abstractive-Text-Summarisation-Using-T5-Transformers/blob/main/Abstractive_Text_Summarisation_Using_T5_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei3WevczRiwP",
        "outputId": "ce08b9b2-0aec-406a-f930-e402636b410a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 32.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 71.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 32.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement datsets (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for datsets\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install datsets transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
        "\n",
        "# text to summarise \n",
        "text = input(\"Enter the Text:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJhCTmSxRuiV",
        "outputId": "9eee5aa7-bd75-46ff-e263-4eaf0c4c6ab4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the Text:In the future, cochlear implants could be tuned to pick up really low frequencies, such as those used by elephants, or really high ones, such as those used by dolphins. Bionic eyes could be built to allow humans to see ultraviolet rays (as butterflies, reindeer, dogs, and other animals can) and infrared light (as certain snakes, fish, and mosquitoes can).  Some researchers think we may eventually install a port in our brains that would allow us to swap in different sensors when we need them. “Maybe there’s a Swiss Army Knife of sensors that you carry with you,” says Rajesh P. N. Rao, the director of the National Science Foundation’s Center for Sensorimotor Neural Engineering. You might rely on a distance sensor when climbing a mountain, then plug in night vision after dark. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating model and tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8h5rB-eS_iT",
        "outputId": "d5100e2e-92ab-4e2f-ff28-fb8395e5cdee"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:174: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stext = \"Summarise:\" + text\n",
        "stext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "uTGWzmaJTYmc",
        "outputId": "221bdda1-bc12-439e-c40e-989bc69c69b7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Summarise:In the future, cochlear implants could be tuned to pick up really low frequencies, such as those used by elephants, or really high ones, such as those used by dolphins. Bionic eyes could be built to allow humans to see ultraviolet rays (as butterflies, reindeer, dogs, and other animals can) and infrared light (as certain snakes, fish, and mosquitoes can).  Some researchers think we may eventually install a port in our brains that would allow us to swap in different sensors when we need them. “Maybe there’s a Swiss Army Knife of sensors that you carry with you,” says Rajesh P. N. Rao, the director of the National Science Foundation’s Center for Sensorimotor Neural Engineering. You might rely on a distance sensor when climbing a mountain, then plug in night vision after dark. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding the input text \n",
        "input_ids = tokenizer.encode(stext, return_tensors = 'pt', max_length=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFMMqBYEXBWj",
        "outputId": "57322a8d-aa65-4039-e2bf-60796554647f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating summary ids\n",
        "summary_ids = model.generate(input_ids, max_length = 180, num_beams=int(8))\n",
        "summary_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb_OBTz3XRwW",
        "outputId": "a034a390-1c49-4a5d-89b8-21eb48d80825"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    0, 32099,    10,  1570,     8,   647,     6,   576,   524,   109,\n",
              "           291, 19136,   228,    36, 14007,    12,  1432,    95,   310,   731,\n",
              "         23446,     6,   224,    38,   273,   261,    57, 17926,     7,     6,\n",
              "            42,   310,   306,  2102,     6,   224,    38,   273,   261,    57,\n",
              "         25903,     7,     3,     5,  3318,  2532,  2053,   228,    36,  1192,\n",
              "            12,   995,  6917,    12,   217, 31728,     3,  2866,     7,    41,\n",
              "             9,     7, 27026,     6,  7101,   221,    49,     6,  3887,    54,\n",
              "            61,    11,    16,    89, 11096,    26,   659,    41,     9,     7,\n",
              "           824, 17599,     7,     6,  2495,     6,    11, 22315,    15,     7,\n",
              "            54,   137,   128,  4768,   317,    62,   164,  3725,  2438,     3,\n",
              "             9,  2147,    16,    69,  2241,     7,    24,   133,   995,   178,\n",
              "            12, 15959,    16,   315,     1]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "print(t5_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJCUW4u4Xv2v",
        "outputId": "7213b825-6184-45dc-a367-fd14b5fd1558"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":In the future, cochlear implants could be tuned to pick up really low frequencies, such as those used by elephants, or really high ones, such as those used by dolphins. Bionic eyes could be built to allow humans to see ultraviolet rays (as butterflies, reindeer, dogs can) and infrared light (as certain snakes, fish, and mosquitoes can). some researchers think we may eventually install a port in our brains that would allow us to swap in different\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Summarised text is:\")\n",
        "print(t5_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TG7wjqyYDjR",
        "outputId": "5c2c54a6-5409-45af-8b9c-66d87a82a6a4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarised text is:\n",
            ":In the future, cochlear implants could be tuned to pick up really low frequencies, such as those used by elephants, or really high ones, such as those used by dolphins. Bionic eyes could be built to allow humans to see ultraviolet rays (as butterflies, reindeer, dogs can) and infrared light (as certain snakes, fish, and mosquitoes can). some researchers think we may eventually install a port in our brains that would allow us to swap in different\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNGQRJXTedCu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}